name: Installation Test

permissions:
  contents: read

# Cancel any preceding run on the pull request after a new commit is pushed.
concurrency:
  group: installation-test-${{ github.event.pull_request.number || github.ref }}-${{ github.event_name }}

  # Don't cancel if running on a push to the main branch.
  cancel-in-progress: ${{ (github.event.pull_request.head.ref || github.ref) != 'refs/heads/main' }}


on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  build:
    uses: ./.github/workflows/build-python.yml
    with:
      python-version: "3.12"

  test-install:
    needs: build
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.12"]

    steps:
      #
      # ─────────────────────────────────────
      # Shared Steps (all OSes)
      # ─────────────────────────────────────
      #
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        id: setup-python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Show Python version
        run: python --version

      - name: Download built distributions
        uses: actions/download-artifact@v4
        with:
          name: python-package-dist

      #
      # ─────────────────────────────────────
      # Linux Steps
      # ─────────────────────────────────────
      #
      - name: Linux - Start Ollama
        if: matrix.os == 'ubuntu-latest'
        shell: bash
        run: |
          docker pull ollama/ollama
          docker run -d --name ollama -p 11434:11434 ollama/ollama

      - name: Linux - Wait for Ollama and pull models
        if: matrix.os == 'ubuntu-latest'
        shell: bash
        run: |
          set -eo pipefail
          until curl -s http://localhost:11434/ > /dev/null; do
            echo "Ollama not up yet, sleeping..."
            sleep 1
          done

          curl -sSf http://localhost:11434/api/pull -d '{"name": "qwen3:0.6b"}' -v
          curl -sSf http://localhost:11434/api/pull -d '{"name": "nomic-embed-text"}' -v

      - name: Linux - Test installation
        if: matrix.os == 'ubuntu-latest'
        shell: bash
        run: |
          set -eo pipefail
          whl_name=$(ls *server*.whl)
          python -m pip install "$whl_name"

      #
      # ─────────────────────────────────────
      # Windows Steps
      # ─────────────────────────────────────
      #
      - name: Windows - Setup Miniconda
        if: matrix.os == 'windows-latest'
        uses: conda-incubator/setup-miniconda@v3
        with:
          python-version: ${{ matrix.python-version }}
          auto-update-conda: true
          run-post: false

      - name: Windows - Set up dev tools
        if: matrix.os == 'windows-latest'
        uses: ilammy/msvc-dev-cmd@v1

      - name: Windows - Install Ollama
        if: matrix.os == 'windows-latest'
        shell: bash
        run: |
          set -eo pipefail
          winget install Ollama.Ollama --accept-source-agreements

          until curl -s http://localhost:11434/ > /dev/null; do
            echo "Ollama not up yet, sleeping..."
            sleep 1
          done

          curl -sSf http://localhost:11434/api/pull -d '{"name":"qwen3:0.6b"}'
          curl -sSf http://localhost:11434/api/pull -d '{"name":"nomic-embed-text"}'

      - name: Windows - Install the package
        if: matrix.os == 'windows-latest'
        shell: bash
        run: |
          set -eo pipefail
          export PYTHONUTF8=1
          whl_name=$(ls *server*.whl)
          python -m pip install "$whl_name"

      #
      # ─────────────────────────────────────
      # macOS Steps
      # ─────────────────────────────────────
      #
      - name: macOS - Install Ollama
        if: matrix.os == 'macos-latest'
        run: |
          set -eo pipefail
          brew install ollama
          brew services start ollama

          until curl -s http://localhost:11434/ > /dev/null; do
            sleep 1
          done

          curl -sSf http://localhost:11434/api/pull -d '{"name":"qwen3:0.6b"}'
          curl -sSf http://localhost:11434/api/pull -d '{"name":"nomic-embed-text"}'

      - name: macOS - Test installation
        if: matrix.os == 'macos-latest'
        shell: bash
        run: |
          set -eo pipefail
          whl_name=$(ls *server*.whl)
          python -m pip install "$whl_name"

      #
      # ─────────────────────────────────────
      # Shared Steps (all OSes)
      # ─────────────────────────────────────
      #

      - name: Run memmachine-configure
        shell: bash
        run: |
          memmachine-configure << EOF
          y
          Ollama
          qwen3:0.6b
      
          http://localhost:11434/v1
          nomic-embed-text
          768
          localhost
          8080
          EOF

      - name: Wait for Neo4j to be ready
        uses: nick-fields/retry@v3
        with:
          max_attempts: 12          # 12 × 5s = 60 seconds
          retry_wait_seconds: 5
          timeout_seconds: 5
          shell: bash
          command: |
            echo "Checking Neo4j Bolt port on localhost:7687..."
            curl -sf http://localhost:7474 || exit 1

      - name: Start memmachine-server
        shell: bash
        run: |
          set -eo pipefail
          echo "Starting memmachine-server..."
          memmachine-server >server-out.log 2>&1 &
          echo $! > server.pid
          echo "Server PID: $(cat server.pid)"

      - name: Wait for server to be ready
        uses: nick-fields/retry@v3
        with:
          max_attempts: 30          # 30 × 10s = 5 minutes
          retry_wait_seconds: 10
          timeout_seconds: 10
          shell: bash
          command: |
            set -eo pipefail

            SERVER_URL="http://127.0.0.1:8080/api/v2/projects/list"

            echo "Checking server readiness..."

            http_code=$(curl -X POST -s -o curl_body.tmp -w "%{http_code}" "$SERVER_URL" || true)
            body=$( [ -f curl_body.tmp ] && cat curl_body.tmp || echo "empty body" )
            rm -f curl_body.tmp

            if [ "$http_code" != "200" ]; then
              echo "Server not ready yet (HTTP $http_code)"
              echo "===== Response Body ====="
              echo "$body"
              exit 1   # triggers retry
            fi

            echo "Server is ready!"
            echo "===== Server Response ====="
            echo "$body"

      - name: Install uv
        shell: bash
        run: pip install uv

      - name: Create uv virtual environment
        shell: bash
        run: uv venv

      - name: Run REST client integration tests
        shell: bash
        run: |
          uv pip install pytest
          uv run pytest tests/memmachine/rest_client/test_integration_complete.py -v --integration -m integration

      - name: Stop memmachine-server
        if: always()
        shell: bash
        run: |
          if [[ -f server.pid ]]; then
            kill "$(cat server.pid)" || true
          fi

      - name: Upload server log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: memmachine-server-logs-installation-${{ matrix.os }}
          path: server-out.log
