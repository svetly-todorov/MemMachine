---
title: "Quickstart Guide"
description: "Start using MemMachine's personalized memory in minutes"
icon: "circle-play"
---

## Installation


### Prerequisites

Before installing MemMachine, ensure you have the following prerequisites:

- **Python 3.12+** - MemMachine requires Python 3.12 or higher
- **OpenAI API Key** - For language models and embeddings
<Note> MemMachine itself is free to install, but please note that tokens are consumed when you use the software. </Note>

### Download and Start Using MemMachine
This method is recommended for most users.
<Steps>
  <Step title="Have Docker and Docker Compose Installed">
      Make sure that you have [Docker](https://docs.docker.com/engine/install/) and [Docker Compose](https://docs.docker.com/compose/install/) installed on your machine.
  </Step>
  <Step title="Download MemMachine and Run the Script">
      Download MemMachine.git from GitHub, navigate to the project directory, and run the `memmachine-compose.sh` script:
        ```bash
        $ git clone https://github.com/MemMachine/MemMachine.git
        $ cd MemMachine
        $ ./memmachine-compose.sh
        ```
      That's it!  The script will walk you through all of the remaining steps and check the health of your memmachine installation and configuration.        
  </Step>
  <Step title="The MemMachine-compose.sh Script">
    The `MemMachine-compose.sh` script does more than simply install memmachine, although that is it's default behavior.  As the commands associated with this script (shown below) describe, it can be used for stopping, restarting, viewing logs, and cleaning up your memmachine installation.
    ```sh
      $ ./memmachine-compose.sh --help
      MemMachine Docker Startup Script
      
      Usage: ./memmachine-compose.sh [command]
      
      Commands:
        (no args)  Start MemMachine services
        stop       Stop MemMachine services
        restart    Restart MemMachine services
        logs       Show service logs
        clean      Remove all services and data
        help       Show this help message
    ```
  </Step>
</Steps>

### Hello World Examples
Validate that your installation is working by following one of the examples below. Each example demonstrates how to add, search, and delete memory episodes using different interfaces: RESTful API, MCP Server, and Python SDK.

<Tabs>
  <Tab title="RESTful API" icon="server">
    ### Hello World: A Guide to the MemMachine RESTful API

This guide provides a quick and simple way to get started with the MemMachine RESTful API using `curl` commands.

### Prerequisites

First, make sure your FastAPI application is running. Open your terminal, navigate to the directory containing your `app.py` file, and run the following command. The output should confirm that the server is listening for requests.

```
uvicorn app:app --reload
```
<Steps>
<Step title="Get All Sessions">

The simplest way to start is by checking for existing sessions. This `GET` request doesn't require any data. You will likely see an empty list since no sessions have been created yet.

```
curl http://127.0.0.1:8000/v1/sessions
```
</Step>
<Step title="Add a New Memory">

This is where you'll create your first memory episode. The `POST /v1/memories` endpoint requires a JSON body that includes session details, a producer, a recipient, and the content of the memory itself.

**Command:**

```
curl -X POST "http://127.0.0.1:8000/v1/memories" \
-H "Content-Type: application/json" \
-d '{
  "session": {
    "group_id": "test_group",
    "agent_id": ["test_agent"],
    "user_id": ["test_user"],
    "session_id": "session_123"
  },
  "producer": "test_user",
  "produced_for": "test_agent",
  "episode_content": "This is a simple test memory.",
  "episode_type": "message",
  "metadata": {}
}'
```

**Expected Output:**

You will receive an empty `200 OK` response, confirming the memory was added successfully.
</Step>
<Step title="Search for the Memory">

Now that a memory has been added, let's try to find it. The `POST /v1/memories/search` endpoint also requires a JSON body to specify the search query and session.

**Command:**

```
curl -X POST "http://127.0.0.1:8000/v1/memories/search" \
-H "Content-Type: application/json" \
-d '{
  "session": {
    "group_id": "test_group",
    "agent_id": ["test_agent"],
    "user_id": ["test_user"],
    "session_id": "session_123"
  },
  "query": "simple test memory",
  "filter": {},
  "limit": 5
}'
```

**Expected Output:**

You should see a `200 OK` response containing the search results, including the memory episode you just added. The output will be formatted as a JSON object, confirming that your memory was successfully found.
</Step>
<Step title=" Delete the Session Data">

To clean up after your test, you can use the `DELETE /v1/memories` endpoint. This also requires a JSON body to specify which session's data should be removed.

**Command:**

```
curl -X DELETE "http://127.0.0.1:8000/v1/memories" \
-H "Content-Type: application/json" \
-d '{
  "session": {
    "group_id": "test_group",
    "agent_id": ["test_agent"],
    "user_id": ["test_user"],
    "session_id": "session_123"
  }
}'
```
</Step>
</Steps>
  </Tab>
  <Tab title="MCP Server" icon="terminal">
    ### Hello World: A Guide to the MemMachine MCP Server API

This guide provides a quick and simple way to get started with the MemMachine Model Content Protocol (MCP) Server API using `curl` commands.

### Prerequisites

First, ensure your FastAPI application is running. Open your terminal, navigate to the directory containing your `app.py` file, and run the following command. The output should confirm that the server is listening for requests.

```
uvicorn app:app --reload
```
<Steps>
<Step title="Get All Sessions">

The simplest way to start is by checking for existing sessions. This is an MCP **resource**, which returns a list of all available sessions.

**Command:**

```
curl http://127.0.0.1:8000/mcp/sessions
```

**Expected Output:**

You will likely see an empty list since no sessions have been created yet.
</Step>
<Step title="Add a New Memory">

This is where you'll use an MCP **tool** to create your first memory episode. The `mcp_add_session_memory` tool is invoked with a `POST` request to its dedicated endpoint.

**Command:**

```
curl -X POST "http://127.0.0.1:8000/mcp/add_session_memory" \
-H "Content-Type: application/json" \
-d '{
  "session": {
    "group_id": "test_group",
    "agent_id": ["test_agent"],
    "user_id": ["test_user"],
    "session_id": "session_123"
  },
  "producer": "test_user",
  "produced_for": "test_agent",
  "episode_content": "This is a simple test memory.",
  "episode_type": "message",
  "metadata": {}
}'
```

**Expected Output:**

You will receive a JSON response confirming the status. A status of `0` indicates success.

```
{
  "status": 0,
  "error_msg": ""
}
```
</Step>
<Step title="Search for the Memory">

Now that a memory has been added, let's use another MCP **tool** to find it. The `mcp_search_session_memory` tool is designed for this purpose.

**Command:**

```
curl -X POST "http://127.0.0.1:8000/mcp/search_session_memory" \
-H "Content-Type: application/json" \
-d '{
  "session": {
    "group_id": "test_group",
    "agent_id": ["test_agent"],
    "user_id": ["test_user"],
    "session_id": "session_123"
  },
  "query": "simple test memory",
  "filter": {},
  "limit": 5
}'
```

**Expected Output:**

You should see a `200 OK` response containing the search results, including the memory episode you just added.
</Step>
<Step title="Delete the Session Data">

To clean up after your test, use the `mcp_delete_session_data` **tool**. This is a great way to ensure your database remains clean.

**Command:**

```
curl -X POST "http://127.0.0.1:8000/mcp/delete_session_data" \
-H "Content-Type: application/json" \
-d '{
  "session": {
    "group_id": "test_group",
    "agent_id": ["test_agent"],
    "user_id": ["test_user"],
    "session_id": "session_123"
  }
}'
```

**Expected Output:**

You will receive a JSON response confirming the status of the deletion. A status of `0` indicates that the data was deleted successfully.

```
{
  "status": 0,
  "error_msg": ""
}
```
</Step>
</Steps>
  </Tab>
  <Tab title="PythonSDK" icon="python">
    Below is a short python script that demonstrates how to use both Episodic Memory and Profile Memory from the MemMachine Python SDK.

    <Note>Make sure to have your `.env` file and `cfg.yml` configuration file set up as described in the installation steps.</Note>
    
  ```python HelloWorld.py expandable
    from dotenv import load_dotenv
    import os
    from importlib import import_module

    from memmachine.common.embedder.openai_embedder import OpenAIEmbedder
    from memmachine.common.language_model.openai_language_model import (
      OpenAILanguageModel,
    )
    from memmachine.episodic_memory.data_types import ContentType
    from memmachine.episodic_memory.episodic_memory import (
      AsyncEpisodicMemory,
      EpisodicMemory,
    )
    from memmachine.episodic_memory.episodic_memory_manager import (
      EpisodicMemoryManager,
    )
    from memmachine.profile_memory.profile_memory import ProfileMemory

    async def episodic_memory_test(config_path: str):
      manager = EpisodicMemoryManager.create_episodic_memory_manager(config_path)
      inst: EpisodicMemory = await manager.get_episodic_memory_instance(
          group_id="test_group",
          agent_id=["test_agent"],
          user_id=["test_user1", "test_user2"],
          session_id="test_session",
      )
      async with AsyncEpisodicMemory(inst) as inst:
          success = await inst.add_memory_episode(
              producer="test_user1",
              produced_for="test_user2",
              episode_content="test_content",
              episode_type="test_type",
              content_type=ContentType.STRING
          )
          print(success)
          success = await inst.add_memory_episode(
            producer="test_user2",
            produced_for="test_user1",
            episode_content="test_content2",
            episode_type="test_type",
            content_type=ContentType.STRING
        )
        print(success)
        res = await inst.query_memory("test_query")
        print(res)

        usr_filter = {"producer": "test_user1"}
        res = await inst.query_memory("test_query", filter=usr_filter)
        print(res)

  async def profile_memory_test():
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    model_name = "gpt-4.1-mini"
    llm_model = OpenAILanguageModel({"api_key": api_key, "model": model_name})
    embeddings = OpenAIEmbedder({"api_key": api_key})
    profile_memory = ProfileMemory(
        model=llm_model,
        embeddings=embeddings,
        db_config={
            "host": os.getenv("POSTGRES_HOST"),
            "port": os.getenv("POSTGRES_PORT"),
            "user": os.getenv("POSTGRES_USER"),
            "password": os.getenv("POSTGRES_PASS"),
            "database": os.getenv("POSTGRES_DB"),
        },
        prompt_module=import_module(".prompt.profile_prompt", __package__),
    )
    await profile_memory.add_persona_message(
            str("Persona message"),
            {},
            user_id="user1",
        )
    
    await profile_memory.semantic_search("test_query", user_id="user1")



  async def main():
    await episodic_memory_test("cfg.yml")
    await profile_memory_test()

  if __name__ == "__main__":
    import asyncio
    asyncio.run(main())

    ```

    Once the file is in your directory, execute it to see the text output it generates:
    ```bash
    python3 ./HelloWorld.py
    ```
  </Tab>
</Tabs>

### Troubleshooting

#### Common Issues

1. **Neo4j Connection Error**: Ensure the Neo4j host in `configuration.yml` is set to `memmachine-neo4j-custom` (not `localhost`)

2. **OpenAI API Key Error**: Make sure you have a valid OpenAI API key and it's correctly set in both the `.env` file and `configuration.yml`

3. **Port Access Issues**: If you can't access the API, ensure the MemMachine container is running on the `memmachine-network` and port 8080 is accessible

4. **Container Network Issues**: Make sure both containers are on the same Docker network (`memmachine-network`)

#### Useful Commands

- Check container status: `docker ps`
- View container logs: `docker logs <container_id>`
- Stop containers: `docker stop <container_id>`
- Remove containers: `docker rm <container_id>`
- Check available API endpoints: `curl -s http://localhost:8080/openapi.json | jq '.paths | keys'
