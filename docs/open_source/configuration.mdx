---
title: "Configuration"
description: "Fine-Tuning Your MemMachine API"
icon: "gear"
---

## MemMachine Configuration

MemMachine's configuration is managed through a `cfg.yml` file, which allows for fine-tuning various aspects of the system. The new configuration structure, introduced in v0.2, emphasizes modularity and centralized resource definitions, making it easier to manage and scale your memory solutions.

All configuration items are organized under top-level keys in the `cfg.yml` file. References between components are made using string IDs, promoting reusability and clarity.

### Configuration Sections

<AccordionGroup>
  <Accordion title="Episodic Memory">
    Configuration for the episodic memory service, which handles event-based memories.

    ```yaml
    episodic_memory:
      enabled: true # Whether episodic memory is enabled (default: true)
      metrics_factory_id: prometheus # ID of the metrics factory (default: "prometheus")
      long_term_memory_enabled: true # Whether long-term memory is enabled within episodic memory (default: true)
      short_term_memory_enabled: true # Whether short-term memory is enabled within episodic memory (default: true)
      long_term_memory: # Configuration for long-term memory
        vector_graph_store: my-neo4j-store # ID of the VectorGraphStore from 'resources.databases'
        embedder: my-openai-embedder # ID of the Embedder from 'resources.embedders'
        reranker: my-rrf-reranker # ID of the Reranker from 'resources.rerankers'
      short_term_memory: # Configuration for short-term memory
        llm_model: my-summarization-llm # ID of the Language Model from 'resources.language_models'
        summary_prompt_system: |
          You are a helpful assistant that summarizes conversational turns.
          Summarize the following conversation for an AI agent.
        summary_prompt_user: |
          Summarize this conversation:
          {{ conversation_history }}
        message_capacity: 64000 # Maximum length of short-term memory (default: 64000)
    ```

    **Parameters:**
    | Parameter                       | Description                                                                 | Default      |
    |---------------------------------|-----------------------------------------------------------------------------|--------------|
    | `enabled`                       | Whether the episodic memory service is enabled.                             | `true`       |
    | `metrics_factory_id`            | The ID of the metrics factory to use for monitoring.                        | `"prometheus"` |
    | `long_term_memory_enabled`      | Whether long-term memory is enabled within episodic memory.                 | `true`       |
    | `short_term_memory_enabled`     | Whether short-term memory is enabled within episodic memory.                | `true`       |
    | `long_term_memory.vector_graph_store` | The ID of a database defined in `resources.databases` for long-term storage. | *Required* |
    | `long_term_memory.embedder`     | The ID of an embedder defined in `resources.embedders` for creating embeddings. | *Required* |
    | `long_term_memory.reranker`     | The ID of a reranker defined in `resources.rerankers` for search result re-ranking. | *Required* |
    | `short_term_memory.llm_model`   | The ID of a language model defined in `resources.language_models` for summarization. | *Required* |
    | `short_term_memory.summary_prompt_system` | The system prompt template for summarizing short-term memories. | (internal default) |
    | `short_term_memory.summary_prompt_user` | The user prompt template for summarizing short-term memories.   | (internal default) |
    | `short_term_memory.message_capacity` | The maximum character capacity for short-term memory.                     | `64000`      |

  </Accordion>

  <Accordion title="Semantic Memory">
    Configuration for the semantic memory service, which handles declarative, knowledge-based memories.

    ```yaml
    semantic_memory:
      database: my-postgres-db # ID of the database from 'resources.databases'
      llm_model: my-semantic-llm # ID of the Language Model from 'resources.language_models'
      embedding_model: my-openai-embedder # ID of the Embedder from 'resources.embedders'
    ```

    **Parameters:**
    | Parameter           | Description                                                                 | Default    |
    |---------------------|-----------------------------------------------------------------------------|------------|
    | `database`          | The ID of a database defined in `resources.databases` for semantic storage. | *Required* |
    | `llm_model`         | The ID of a language model defined in `resources.language_models` for semantic processing. | *Required* |
    | `embedding_model`   | The ID of an embedder defined in `resources.embedders` for creating embeddings. | *Required* |
  </Accordion>

  <Accordion title="Logging">
    Manages the path and level of application logging.

    ```yaml
    logging:
      level: info # Log level: debug, info, warning, error, critical (default: info)
      format: "%(asctime)s [%(levelname)s] %(name)s - %(message)s" # Log format string
      path: MemMachine.log # Path to log file (empty logs to stdout only)
    ```

    **Parameters:**
    | Parameter | Description                            | Default                    |
    |-----------|----------------------------------------|----------------------------|
    | `level`   | The minimum level of messages to log.  | `info`                     |
    | `format`  | The format string for log messages.    | `%(asctime)s [%(levelname)s] %(name)s - %(message)s` |
    | `path`    | The file path to write logs to. If empty, logs are sent to stdout. | `MemMachine.log`           |
  </Accordion>

  <Accordion title="Prompts">
    Manages the default prompts used for various memory types.

    ```yaml
    prompt:
      profile:
        - profile_prompt
        - writing_assistant_prompt
      role: []
      session: []
      episode_summary_system_prompt_path: # Path to custom system prompt file
      episode_summary_user_prompt_path: # Path to custom user prompt file
    ```

    **Parameters:**
    | Parameter                           | Description                                                            | Default                      |
    |-------------------------------------|------------------------------------------------------------------------|------------------------------|
    | `profile`                           | List of predefined prompt IDs for semantic user profile memory.          | `["profile_prompt", "writing_assistant_prompt"]` |
    | `role`                              | List of predefined prompt IDs for semantic role memory.                | `[]`                         |
    | `session`                           | List of predefined prompt IDs for semantic session memory.             | `[]`                         |
    | `episode_summary_system_prompt_path`| Path to a custom file containing the system prompt for episode summarization. | (internal default)           |
    | `episode_summary_user_prompt_path`  | Path to a custom file containing the user prompt for episode summarization.   | (internal default)           |
  </Accordion>

  <Accordion title="Session Manager">
    Configuration for the session management database.

    ```yaml
    session_manager:
      database: my-postgres-db # ID of the database from 'resources.databases'
    ```

    **Parameters:**
    | Parameter | Description                                                                 | Default    |
    |-----------|-----------------------------------------------------------------------------|------------|
    | `database`| The ID of a database defined in `resources.databases` for session data storage. | *Required* |
  </Accordion>

  <Accordion title="Episode Store">
    Configuration for the database storing raw episode data.

    ```yaml
    episode_store:
      database: my-postgres-db # ID of the database from 'resources.databases'
    ```

    **Parameters:**
    | Parameter | Description                                                                 | Default    |
    |-----------|-----------------------------------------------------------------------------|------------|
    | `database`| The ID of a database defined in `resources.databases` for episode storage. | *Required* |
  </Accordion>

  <Accordion title="Resources">
    This section centralizes the definitions of various external resources, which can then be referenced by ID in other parts of the configuration.

    ### Databases
    Defines connections to various database backends (Neo4j, PostgreSQL, SQLite).

    ```yaml
    resources:
      databases:
        my-neo4j-store:
          provider: neo4j
          config:
            host: localhost
            port: 7687
            user: neo4j
            password: your-neo4j-password
        my-postgres-db:
          provider: postgres
          config:
            host: localhost
            port: 5432
            user: postgres
            password: your-postgres-password
            db_name: memmachine_db
        my-sqlite-db:
          provider: sqlite
          config:
            path: ./data/memmachine.db
    ```

    **Parameters for each database ID (e.g., `my-neo4j-store`):**
    | Parameter     | Description                                                          | Default     |
    |---------------|----------------------------------------------------------------------|-------------|
    | `provider`    | The database provider type: `neo4j`, `postgres`, or `sqlite`.        | *Required*  |
    | `config`      | A dictionary containing provider-specific configuration.             | *Required*  |
    | `config.host` | Hostname for the database (e.g., `localhost`).                     | Depends on provider |
    | `config.port` | Port number for the database connection.                           | Depends on provider |
    | `config.user` | Username for database authentication.                              | Depends on provider |
    | `config.password`| Password for database authentication.                            | Depends on provider |
    | `config.db_name`| Database name (for `postgres`).                                  | `memmachine_db` for postgres |
    | `config.path` | File path for SQLite database (for `sqlite`).                      | `./data/memmachine.db` |


    ### Embedders
    Defines various embedding models, which can be used to generate vector representations of text.

    ```yaml
    resources:
      embedders:
        my-openai-embedder:
          provider: openai
          config:
            model: text-embedding-3-small
            api_key: your-openai-api-key
        my-bedrock-embedder:
          provider: amazon-bedrock
          config:
            region: us-east-1
            aws_access_key_id: YOUR_AWS_ACCESS_KEY_ID
            aws_secret_access_key: YOUR_AWS_SECRET_ACCESS_KEY
            model_id: amazon.titan-embed-text-v2:0
        my-sentence-transformer-embedder:
          provider: sentence-transformer
          config:
            model: all-MiniLM-L6-v2
    ```

    **Parameters for each embedder ID (e.g., `my-openai-embedder`):**
    | Parameter         | Description                                                          | Default                  |
    |-------------------|----------------------------------------------------------------------|--------------------------|
    | `provider`        | The embedder provider type: `openai`, `amazon-bedrock`, `sentence-transformer`. | *Required*               |
    | `config`          | A dictionary containing provider-specific configuration.             | *Required*               |
    | `config.model`    | Model name (e.g., `text-embedding-3-small` for OpenAI, `all-MiniLM-L6-v2` for sentence-transformer). | Depends on provider |
    | `config.api_key`  | API key for OpenAI.                                                  | *Required for OpenAI*    |
    | `config.region`   | AWS region for Bedrock.                                              | *Required for Bedrock*   |
    | `config.aws_access_key_id` | AWS access key ID for Bedrock.                               | *Required for Bedrock*   |
    | `config.aws_secret_access_key` | AWS secret access key for Bedrock.                       | *Required for Bedrock*   |
    | `config.model_id` | Bedrock model ID.                                                    | `amazon.titan-embed-text-v2:0` for Bedrock |


    ### Language Models
    Defines various language models for tasks like summarization and generation.

    ```yaml
    resources:
      language_models:
        my-openai-llm:
          provider: openai-chat-completions
          config:
            model: gpt-4o-mini
            api_key: your-openai-api-key
        my-bedrock-llm:
          provider: amazon-bedrock
          config:
            region: us-east-1
            aws_access_key_id: YOUR_AWS_ACCESS_KEY_ID
            aws_secret_access_key: YOUR_AWS_SECRET_ACCESS_KEY
            model_id: anthropic.claude-3-sonnet-20240229-v1:0
            inference_config:
              max_tokens: 2000
              temperature: 0.7
    ```

    **Parameters for each language model ID (e.g., `my-openai-llm`):**
    | Parameter         | Description                                                          | Default                  |
    |-------------------|----------------------------------------------------------------------|--------------------------|
    | `provider`        | The language model provider type: `openai-responses`, `openai-chat-completions`, `amazon-bedrock`. | *Required*               |
    | `config`          | A dictionary containing provider-specific configuration.             | *Required*               |
    | `config.model`    | Model name (e.g., `gpt-4o-mini` for OpenAI).                         | Depends on provider |
    | `config.api_key`  | API key for OpenAI.                                                  | *Required for OpenAI*    |
    | `config.region`   | AWS region for Bedrock.                                              | *Required for Bedrock*   |
    | `config.aws_access_key_id` | AWS access key ID for Bedrock.                               | *Required for Bedrock*   |
    | `config.aws_secret_access_key` | AWS secret access key for Bedrock.                       | *Required for Bedrock*   |
    | `config.model_id` | Bedrock model ID.                                                    | `anthropic.claude-3-sonnet-20240229-v1:0` for Bedrock |
    | `config.inference_config`| Inference parameters for Bedrock (e.g., `max_tokens`, `temperature`). | (None)                   |


    ### Rerankers
    Defines various reranking strategies used to reorder search results for improved relevance.

    ```yaml
    resources:
      rerankers:
        my-rrf-reranker:
          provider: rrf-hybrid
          config:
            reranker_ids:
              - my-bm25-reranker
              - my-cross-encoder-reranker
        my-bm25-reranker:
          provider: bm25
          config:
            k1: 1.5
            b: 0.75
        my-cross-encoder-reranker:
          provider: cross-encoder
          config:
            model_name: cross-encoder/qnli-electra-base
        my-identity-reranker:
          provider: identity
        my-bedrock-reranker:
          provider: amazon-bedrock
          config:
            region: us-east-1
            aws_access_key_id: YOUR_AWS_ACCESS_KEY_ID
            aws_secret_access_key: YOUR_AWS_SECRET_ACCESS_KEY
            model_id: amazon.rerank-v1:0
    ```

    **Parameters for each reranker ID (e.g., `my-rrf-reranker`):**
    | Parameter         | Description                                                          | Default                  |
    |-------------------|----------------------------------------------------------------------|--------------------------|
    | `provider`        | The reranker provider type: `bm25`, `amazon-bedrock`, `cross-encoder`, `embedder`, `identity`, `rrf-hybrid`. | *Required*               |
    | `config`          | A dictionary containing provider-specific configuration.             | *Required*               |
    | `config.reranker_ids` | List of reranker IDs to combine for `rrf-hybrid`.              | *Required for rrf-hybrid*|
    | `config.model_name`| Model name for `cross-encoder`.                                    | Depends on provider |
    | `config.embedder_id`| ID of an embedder for `embedder` reranker.                         | *Required for embedder*  |
    | `config.region`   | AWS region for Bedrock.                                              | *Required for Bedrock*   |
    | `config.aws_access_key_id` | AWS access key ID for Bedrock.                               | *Required for Bedrock*   |
    | `config.aws_secret_access_key` | AWS secret access key for Bedrock.                       | *Required for Bedrock*   |
    | `config.model_id` | Bedrock model ID.                                                    | `amazon.rerank-v1:0` for Bedrock |

  </Accordion>
</AccordionGroup>

## Proxy Configuration

If you are deploying MemMachine behind a corporate proxy, you may need to configure it to route traffic through your proxy server and trust custom Certificate Authorities (CAs).

### Docker Compose

To configure proxies in a Docker Compose setup, add the `HTTP_PROXY`, `HTTPS_PROXY`, and `SSL_CERT_FILE` environment variables to your service definitions. You may also need to mount a custom CA certificate if your proxy performs SSL inspection.

Add the following to your `docker-compose.yml` for the `memmachine` service:

```yaml
services:
  memmachine:
    environment:
      # ... other variables ...
      # Proxy settings
      HTTP_PROXY: ${HTTP_PROXY:-http://proxy.example.com:8080}
      HTTPS_PROXY: ${HTTPS_PROXY:-http://proxy.example.com:8080}
      SSL_CERT_FILE: /app/custom-ca-cert.pem
    volumes:
      # ... other volumes ...
      - ./custom-ca-cert.pem:/app/custom-ca-cert.pem:ro,Z
```

### Standard Installation (Pip/Source)

If you are running MemMachine directly on your host machine (e.g., using `pip` or from source), simply export the standard environment variables before starting the application.

**Linux/MacOS:**
```bash
export HTTP_PROXY="http://proxy.example.com:8080"
export HTTPS_PROXY="http://proxy.example.com:8080"
export SSL_CERT_FILE="/path/to/custom-ca-cert.pem"

memmachine-server
```

**Windows (PowerShell):**
```powershell
$env:HTTP_PROXY = "http://proxy.example.com:8080"
$env:HTTPS_PROXY = "http://proxy.example.com:8080"
$env:SSL_CERT_FILE = "C:\path\to\custom-ca-cert.pem"

memmachine-server
```