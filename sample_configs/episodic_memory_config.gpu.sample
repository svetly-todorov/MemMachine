logging:
  path: mem-machine.log
  level: info #| debug | error

episode_store:
  database: profile_storage

episodic_memory:
  long_term_memory:
    embedder: openai_embedder
    reranker: my_reranker_id
    vector_graph_store: my_storage_id
  short_term_memory:
    llm_model: openai_model
    message_capacity: 500

semantic_memory:
  llm_model: openai_model
  embedding_model: openai_embedder
  database: profile_storage

session_manager:
  database: profile_storage

prompt:
  session:
  - profile_prompt

resources:
  databases:
    profile_storage:
      provider: postgres
      config:
        host: localhost
        port: 5432
        user: postgres
        db_name: postgres
        password: <YOUR_PASSWORD_HERE>
        pool_size: 5
        max_overflow: 10
    my_storage_id:
      provider: neo4j
      config:
        uri: 'bolt://localhost:7687'
        username: neo4j
        password: <YOUR_PASSWORD_HERE>
        range_index_creation_threshold: 10000
        vector_index_creation_threshold: 10000
    sqlite_test:
      provider: sqlite
      config:
        path: sqlite_test.db
  embedders:
    openai_embedder:
      provider: openai
      config:
        model: "text-embedding-3-small"
        api_key: <YOUR_API_KEY>
        base_url: "https://api.openai.com/v1"
        dimensions: 1536
    aws_embedder_id:
      provider: 'amazon-bedrock'
      config:
        region: "us-west-2"
        aws_access_key_id: <AWS_ACCESS_KEY_ID>
        aws_secret_access_key: <AWS_SECRET_ACCESS_KEY>
        model_id: "amazon.titan-embed-text-v2:0"
        similarity_metric: "cosine"
    ollama_embedder:
      provider: openai
      config:
        model: "nomic-embed-text"
        api_key: "EMPTY"
        base_url: "http://host.docker.internal:11434/v1"
        dimensions: 768
    openai_compatible_embedder:
      provider: openai
      config:
        model: "text-embedding-v4"
        api_key: <YOUR_API_KEY>
        base_url: "https://api.openai.com/v1"
        dimensions: 1536
  language_models:
    openai_model:
      provider: openai-responses
      config:
        model: "gpt-4o-mini"
        api_key: <YOUR_API_KEY>
        base_url: "https://api.openai.com/v1"
    aws_model:
      provider: "amazon-bedrock"
      config:
        region: "us-west-2"
        aws_access_key_id: <AWS_ACCESS_KEY_ID>
        aws_secret_access_key: <AWS_SECRET_ACCESS_KEY>
        model_id: "openai.gpt-oss-20b-1:0"
    ollama_model:
      provider: openai-chat-completions
      config:
        model: "llama3"
        api_key: "EMPTY"
        base_url: "http://host.docker.internal:11434/v1"
    openai_compatible_model:
      provider: openai-chat-completions
      config:
        model: "qwen-flash"
        api_key: <YOUR_API_KEY>
        base_url: "https://api.openai.com/v1"
  rerankers:
    my_reranker_id:
      provider: "rrf-hybrid"
      config:
        reranker_ids:
          - id_ranker_id
          - bm_ranker_id
          - ce_ranker_id
    id_ranker_id:
      provider: "identity"
    bm_ranker_id:
      provider: "bm25"
    cohere_reranker_id:
      provider: "cohere"
      config:
        cohere_key: <COHERE_API_KEY>
        model: "rerank-english-v3.0"
    ce_ranker_id:
      provider: "cross-encoder"
      config:
        model_name: "cross-encoder/qnli-electra-base"
    aws_reranker_id:
      provider: "amazon-bedrock"
      config:
        region: "us-west-2"
        aws_access_key_id: <AWS_ACCESS_KEY_ID>
        aws_secret_access_key: <AWS_SECRET_ACCESS_KEY>
        model_id: "amazon.rerank-v1:0"
